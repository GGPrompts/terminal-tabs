# Tabz Backend Configuration
# This file is automatically generated by start-tmux.sh based on your selections

# Logging Configuration
# 0=silent, 1=fatal, 2=error, 3=warn, 4=info, 5=debug
LOG_LEVEL=4

# Optional: Write logs to file (uncomment to enable)
# LOG_FILE=logs/backend.log

# AI Configuration (Experimental)
# Provider: ollama, openai, or openai-compatible
AI_PROVIDER=openai-compatible

# Base URL for AI API (default: Ollama)
AI_BASE_URL=http://localhost:11434/v1

# Model to use
AI_MODEL=qwen2.5-coder:7b

# API Key (optional, required for some providers)
# AI_API_KEY=your-api-key-here

# Temperature (0.0-1.0, lower = more deterministic)
AI_TEMPERATURE=0.7

# Max tokens per response
AI_MAX_TOKENS=500

# Note:
# - Browser console logs are forwarded to backend when LOG_LEVEL >= 4 (info)
# - Use start-tmux.sh to interactively configure logging options
# - To manually set log level, copy this file to .env and edit
